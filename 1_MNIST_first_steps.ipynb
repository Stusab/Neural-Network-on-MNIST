{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Stusab/Neural-Network-on-MNIST/blob/main/1_MNIST_first_steps.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSV_OlCFKOD"
      },
      "source": [
        "# Training a neural network on MNIST with Keras&Tensorflow\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyAWszXJDBZF"
      },
      "source": [
        "In this Notebook you will start playing with the \"Hello World\" of Nueral Networks: The MNIST Dataset. And we will expand from there."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PXUHrp3DBZF"
      },
      "source": [
        "### 1. Classification of hand-written digits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTBSvHcSLBzc"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRSLoGXXDBZG"
      },
      "outputs": [],
      "source": [
        "tf.__version__\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80zHCUbvDBZG"
      },
      "outputs": [],
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(X_train_full, y_train_full), (X_test, y_test) = mnist.load_data()\n",
        "#X_train_full.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0KjuDf7XiqY"
      },
      "outputs": [],
      "source": [
        "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.# we want to have the input between 0 and 1\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "X_test = X_test / 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwWz09nNDBZH"
      },
      "outputs": [],
      "source": [
        "n_rows = 4\n",
        "n_cols = 10\n",
        "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
        "for row in range(n_rows):\n",
        "    for col in range(n_cols):\n",
        "        index = n_cols * row + col\n",
        "        plt.subplot(n_rows, n_cols, index + 1)\n",
        "        plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\")\n",
        "        plt.axis('off')\n",
        "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bZ9GaRCDBZH"
      },
      "outputs": [],
      "source": [
        "plt.imshow(X_train[5], cmap=\"binary\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uzi_WEUFDBZH"
      },
      "outputs": [],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTFoji3INMEM"
      },
      "source": [
        "### Create and train the model\n",
        "Implement an ANN with 2 Hidden Layers, the first with 128 neurons and \"relu\" activation functions. The second layers instead contains 64 neurons (also relu activation function).\n",
        "Don't forget the output layer :)\n",
        "\n",
        "Also, remember that due to the 2D structure of your input data you need to first flatten them. Use the following specific layer at the very beginning inside your Sequential Model:\n",
        "\n",
        "\n",
        "tf.keras.layers.Flatten(input_shape=(28, 28))\n",
        "\n",
        "Notabene: you don't need to provide the input_dim in the first Dense layer, if you start with a Flatten layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGUtUsHXDBZH"
      },
      "outputs": [],
      "source": [
        "# TODO: Define the model architecture here\n",
        "# model =  ...."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NF1I2IdjDBZI"
      },
      "source": [
        "Since my input are 2D images, I need first to \"flatten\" them into a 1-dimensional array. The number of input neurons will be the total number of pixels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLJQ2BbIDBZI"
      },
      "outputs": [],
      "source": [
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHYRFQznDBZI"
      },
      "source": [
        "Define now which cost function to minimize in the .compile method. Take \"sgd\" as optimizer and track the accuracy as metric.\n",
        "\n",
        "For classification:Pay attention to the last layer if sigmoid or softmax is explicitly indicated, then from_logits = False\n",
        "\n",
        "Notabene: Here a Sparse Categorical Crossentropy is used, becuase we are dealing with a multi-class classification If it would be a binary classification, then the loss function (i.e. the cost function) would have been Binary Crossentropy\n",
        "\n",
        "For a full lists of cost functions available in tf.keras (both for Regression and Classification) https://www.tensorflow.org/api_docs/python/tf/keras/losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEKPjR3mDBZI"
      },
      "outputs": [],
      "source": [
        "# TODO: Compile the model with appropriate loss, optimizer, and metrics (the choice of loss function depends on the problem you are facing)\n",
        "# model.compile(...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9lswuT4DBZI"
      },
      "outputs": [],
      "source": [
        "# TODO: Train the model using model.fit\n",
        "# history = model.fit(...) # 1 epoch is a full pass over the whole training set, let's tray for 15 eopchs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4hB8yMWDBZI"
      },
      "outputs": [],
      "source": [
        "# TODO: Evaluate the model on the test dataset\n",
        "# model.evaluate(...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GR8iYyZ9DBZJ"
      },
      "source": [
        "Let's now predict the digits for the first 3 images in the test set. Feel free to check more cases.\n",
        "First we predict the score associated which every category and then we find out which one is the one with highest score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2x50LD3lDBZJ"
      },
      "outputs": [],
      "source": [
        "X_new = X_test[:3]\n",
        "y_proba = model.predict(X_new)\n",
        "y_proba.round(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRj6gzdCDBZJ"
      },
      "outputs": [],
      "source": [
        "y_pred=np.argmax(y_proba,axis=1)\n",
        "\n",
        "#if you are working with binary classification, use instead the following line:\n",
        "#y_pred = (y_proba > 0.5).astype(\"int32\")\n",
        "\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aV-fhuHDBZJ"
      },
      "source": [
        "Let's now visually check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cN1YzS4uDBZJ"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(7.2, 2.4))\n",
        "for index, image in enumerate(X_new):\n",
        "    plt.subplot(1, 3, index + 1)\n",
        "    plt.imshow(image, cmap=\"binary\", interpolation=\"nearest\")\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5cuBVanDBZJ"
      },
      "source": [
        "### Experimental test\n",
        "\n",
        "The final test consist in a \"physical\" test.\n",
        "1) Draw on a piece of paper 1 single digit between 0 and 9.\n",
        "2) Take a picture with your webcam of it\n",
        "3) Test if the neural network can correctly identify also your handwriting\n",
        "\n",
        "\n",
        "To do that you need to preprocess first your image and put it in the right format, by using the Keras function 'load_img'\n",
        "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/load_img\n",
        "ATTENTION: your image need to be resized in the same size that you used for training.... And pay attention to RGB images and grayscale!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xdn0lFD-DBZJ"
      },
      "outputs": [],
      "source": [
        "img = keras.preprocessing.image.load_img(#ADD YOUR CODE)\n",
        "\n",
        "\n",
        "img_array = keras.preprocessing.image.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0) # Create a batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7RUzhWCDBZK"
      },
      "source": [
        "Now you can simply predict the class of your image, as done just before for the MNIST test images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euTAnHbiDBZK"
      },
      "outputs": [],
      "source": [
        "predictions = model(img_array, training = False)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "print(\n",
        "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(np.argmax(predictions,axis=1), 100 * np.max(score))\n",
        ")\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "447ytJDuDBZK"
      },
      "source": [
        "Is the result correct?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUPBdTLmDBZK"
      },
      "source": [
        "### Plot the evolution of accuracy and loss\n",
        "The historical values of accuracy and loss during training and validation are stored during training in the variable \"history\".\n",
        "You can access them through history.history.\n",
        "Use this information to plot and compare the evolution of accuracy and loss for training and validation. What can you learn from this?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSIqGk5ADBZK"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,3))\n",
        "# Plot training & validation accuracy values\n",
        "plt.subplot(121)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(122)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}